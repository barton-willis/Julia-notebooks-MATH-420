{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Page Rank\n",
    "__MATH 420__  <br>\n",
    "_Spring 2021_ <br>\n",
    "\n",
    "\n",
    "We would like a way to assign a numerical value, let's call it the _rank,_ to the popularity of a web page. We'll describe a method that is the  basis of the Google Page Rank.\n",
    "\n",
    "To start our thinking about this, let's imagine that a popular page, say the _Wall Street Journal_ (WSJ) has a link to the _Kearney Hub._  The editor of the _Hub_ will be thrilled with the traffic that might result from being linked from such a popular web page. But if the _Kearney Hub_ links to the _Wall Street Journal,_  I'd guess that the editors of the WSJ would barely notice. So our first insight is that the rank of a page depends on the ranks of the pages that link to it. If a highly ranked page links to the _Kearney Hub,_ for example, it raises the rank of the _Hub._  But if a lowly ranked page links to the _Hub,_ it doesn't affect the rank of the _Hub_ all that much. \n",
    "\n",
    "Our second insight is that if a page links to many pages, that diminishes the influence of a link. A visitor to a page that links to a million other pages, might click on any one of a million links, but a visitor to a page that only links to just ten pages has a good chance of visiting one of these ten pages. So the more links a page has, the less influence it has on the ranks of the pages it links to. We can think of each link from a web page as a vote, with the weight of each vote as $1/n$, where $n$ is the number of links from a web page. Thus the sum of all the votes from each web page is one. \n",
    "\n",
    "Given these insights, let's define the _rank_ of a page to be proportional  to the weighted sum of the ranks that link to it. Again, the weight of each link is the reciprocal of the number of pages it links to. So if a page links to $107$ other pages, the weight of each link is $1/107$.\n",
    "\n",
    "Let's take an example. Let's suppose we have four web pages labeled $A,B,C$, and $D$. \n",
    "\n",
    "Suppose pages $B$ and $C$ link to page $A$, and suppose page $B$ has a weight of $1/2$ (that is, it links to a total of two pages), and page $C$ has a weight of $1/3$ (thus page $C$ links to three pages). Calling the proportionality constant $\\lambda$, the rank of $A$  satisfies\n",
    "$$\n",
    "  \\lambda  \\, \\, \\mbox{rank}(A) = \\frac{1}{2}  \\mbox{rank} (B) + \\frac{1}{3}  \\mbox{rank}(C).\n",
    "$$\n",
    "\n",
    "For the rank of $B$, suppose that pages $A$ and $C$ link to page $B$. And suppose the weight of page $A$ is $1/2$. Then\n",
    "$$\n",
    "  \\lambda  \\, \\, \\mbox{rank}(B) = \\frac{1}{2}  \\mbox{rank} (A) + \\frac{1}{3} \\mbox{rank} (C).\n",
    "$$\n",
    "For the other two pages, let's suppose that \n",
    "$$\n",
    "  \\lambda  \\, \\,  \\mbox{rank}(C) = \\frac{1}{2}  \\mbox{rank} (B) + \\mbox{rank} (D) ,\n",
    "$$\n",
    "$$\n",
    "  \\lambda   \\, \\, \\mbox{rank}(D) = \\frac{1}{2}  \\mbox{rank} (A) +  \\frac{1}{3} \\mbox{rank} (C). \n",
    "$$\n",
    "\n",
    "In matrix notation, our equations are\n",
    "$$\n",
    "  \\lambda \\begin{bmatrix} A \\\\ B \\\\ C \\\\ D \\end{bmatrix} = \\begin{bmatrix} 0 & 1/2 & 1/3 & 0 \\\\ 1/2 & 0 & 1/3 & 0 \\\\ 0 & 1/2 & 0 & 1 \\\\ 1/2 & 0 & 1/3 & 0 \\end{bmatrix} \\begin{bmatrix} A \\\\ B \\\\ C \\\\ D \\end{bmatrix}. \n",
    "$$\n",
    "Here I tired of writing $\\mbox{rank}(A)$, so I wrote $A$ instead; and similarly for the other variables. Since $\\lambda$ is unknown and the equations for $A, B, C$, and $D$ are linear, this is an _eigenvalue problem_. \n",
    "\n",
    "The matrix has several nice properties: (a) every column sum is one (b) all entries are in the interval $[0,1]$. Such a matrix is called a _Markov_ matrix. (See, for example, https://en.wikipedia.org/wiki/Stochastic_matrix). Ou r matrix has an additional property that in each column, every nonzero value is the same. For our matrix, for example, every nonzero member of the first column is $1/2$.\n",
    "\n",
    "The equations for the unknowns $A, B, C$, and $D$ are homogeneous and linear. Accordingly, any multiple of a solution for provides another solution. This freedom allows us to require that the sum of the ranks have a specific value (for example 10).\n",
    "\n",
    "Let's have Julia solve the eigenvalue problem for us. We'll need the package `LinearAlgebra`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the matrix `M` by hand. After that, we can find the eigenvalues and eigenvectors with one command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Array{Float64,2}:\n",
       " 0.0  0.5  0.333333  0.0\n",
       " 0.5  0.0  0.333333  0.0\n",
       " 0.0  0.5  0.0       1.0\n",
       " 0.5  0.0  0.333333  0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = [0 1/2 1/3 0; 1/2 0 1/3 0; 0 1/2 0 1; 1/2 0 1/3 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "F  = eigen(M);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvalues (the value of $\\lambda$) gives the proportionality constant. The eigenvalues are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " -0.5000000062651664\n",
       " -0.4999999937348334\n",
       "  0.0\n",
       "  0.9999999999999998"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Only one eigenvalue is positive, the rest are negative. One eigenvalue is so clost to one, I'd guess that its true value is one. Indeed one is an eigenvalue of _every_ Markov matrix. \n",
    "\n",
    "And the corresponding eigenvectors (the page ranks) are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Array{Float64,2}:\n",
       " -0.288675   0.288675  -0.471405  0.436436\n",
       " -0.288675   0.288675  -0.471405  0.436436\n",
       "  0.866025  -0.866025   0.707107  0.654654\n",
       " -0.288675   0.288675   0.235702  0.436436"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column is an eigenvalue. Column 4, the eigenvector corresponding to the eigenvalue one, consists of entirely positive numbers. It's natural, I think, to require that a rank be nonnegative. Thus, we'll choose the eigenvector corresponding to the eigenvalue one for the ranks.\n",
    "\n",
    "So the eigenvalue corresponding to the eigenvalue 0.9999999999999998 is (the command [:, 4] returns column 4 of a matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.4364357804719847\n",
       " 0.4364357804719847\n",
       " 0.6546536707079773\n",
       " 0.4364357804719847"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = F.vectors[:, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This says Page $C$ has the highest rank (it's rank is about $0.65$ and each of the other ranks is about $0.43$. There is a three way tie for second place.  We might like to normalize the ranks to sum to $10 \\,\\, (= 1 + 2 + 3 + 4)$. A quick way to do this is to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 2.222222222222222\n",
       " 2.222222222222222\n",
       " 3.333333333333334\n",
       " 2.222222222222222"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 * x / sum(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Alternatively, if we want the sum of the ranks to be one, we normalize by dividing by the sum of the ranks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.2222222222222222\n",
       " 0.2222222222222222\n",
       " 0.3333333333333334\n",
       " 0.2222222222222222"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x / sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requiring that the sum of the ranks be 10, the rank of Page $C$ is about $3.3$ and the other ranks are $2.2$.\n",
    "\n",
    "Was it a coincidence that exactly one eigenvalue was positive and one eigenvector had only nonnegative terms?  No, there is a theory. For the theory, see https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem .\n",
    "\n",
    "Eigenvalue problems look somewhat like a fixed point problem, but the eigenvalue alters that somewhat. But for an eigenvalue of one, the eigenvalue problem\n",
    "$$\n",
    "   x = M x\n",
    "$$\n",
    "is _exactly_ the form of a fixed point problem.  Let's try solving our problem using fixed point iteration. Here is a quick to write recursive method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed_point (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fixed_point(M, x0, tol)\n",
    "    x1 = M * x0\n",
    "    @show(x1)\n",
    "    if norm(x1-x0, 2) < tol x1 else fixed_point(M, x1, tol) end\n",
    "end"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's try it--we'll try an initial point of 4[1,0,0,0]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 = [0.0, 0.5, 0.0, 0.5]\n",
      "x1 = [0.25, 0.0, 0.75, 0.0]\n",
      "x1 = [0.25, 0.375, 0.0, 0.375]\n",
      "x1 = [0.1875, 0.125, 0.5625, 0.125]\n",
      "x1 = [0.25, 0.28125, 0.1875, 0.28125]\n",
      "x1 = [0.203125, 0.1875, 0.421875, 0.1875]\n",
      "x1 = [0.234375, 0.2421875, 0.28125, 0.2421875]\n",
      "x1 = [0.21484375, 0.2109375, 0.36328125, 0.2109375]\n",
      "x1 = [0.2265625, 0.228515625, 0.31640625, 0.228515625]\n",
      "x1 = [0.2197265625, 0.21875, 0.3427734375, 0.21875]\n",
      "x1 = [0.2236328125, 0.22412109375, 0.328125, 0.22412109375]\n",
      "x1 = [0.221435546875, 0.22119140625, 0.336181640625, 0.22119140625]\n",
      "x1 = [0.22265625, 0.2227783203125, 0.331787109375, 0.2227783203125]\n",
      "x1 = [0.22198486328125, 0.221923828125, 0.33416748046875, 0.221923828125]\n",
      "x1 = [0.22235107421875, 0.222381591796875, 0.3328857421875, 0.222381591796875]\n",
      "x1 = [0.2221527099609375, 0.222137451171875, 0.3335723876953125, 0.222137451171875]\n",
      "x1 = [0.222259521484375, 0.22226715087890625, 0.3332061767578125, 0.22226715087890625]\n",
      "x1 = [0.22220230102539062, 0.222198486328125, 0.3334007263183594, 0.222198486328125]\n",
      "x1 = [0.22223281860351562, 0.22223472595214844, 0.3332977294921875, 0.22223472595214844]\n",
      "x1 = [0.22221660614013672, 0.2222156524658203, 0.33335208892822266, 0.2222156524658203]\n",
      "x1 = [0.22222518920898438, 0.22222566604614258, 0.33332347869873047, 0.22222566604614258]\n",
      "x1 = [0.22222065925598145, 0.22222042083740234, 0.33333849906921387, 0.22222042083740234]\n",
      "x1 = [0.22222304344177246, 0.222223162651062, 0.3333306312561035, 0.222223162651062]\n",
      "x1 = [0.22222179174423218, 0.2222217321395874, 0.333334743976593, 0.2222217321395874]\n",
      "x1 = [0.2222224473953247, 0.2222224771976471, 0.3333325982093811, 0.2222224771976471]\n",
      "x1 = [0.22222210466861725, 0.22222208976745605, 0.33333371579647064, 0.22222208976745605]\n",
      "x1 = [0.22222228348255157, 0.22222229093313217, 0.3333331346511841, 0.22222229093313217]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.22222228348255157\n",
       " 0.22222229093313217\n",
       " 0.3333331346511841\n",
       " 0.22222229093313217"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_point(M, [1; 0 ; 0; 0], 1.0e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers are familiar! This is exactly the result we got when we normalized by dividing by the sum of the ranks. For our matrix, we can show that if the sum of the members of xx is one, the sum of the members of $Mx$ is also one.\n",
    "\n",
    "> Since started with a vector whose sum of components was one, the method returns a vector that also has a sum of components of one.\n",
    "\n",
    "\n",
    "\n",
    "> We've described what Wikipedia (https://en.wikipedia.org/wiki/PageRank#Simplified_algorithm) refers to the _simplified version_.  \n",
    "\n",
    "The Patent for the Google Page Rank (https://patentimages.storage.googleapis.com/db/8f/cb/dad63e985797ec/US7058628.pdf) replaces the Markov matrix $M$ for the simplified version by \n",
    "$$\n",
    "  \\frac{\\alpha}{N} I  + (1 - \\alpha) M,\n",
    "$$\n",
    "where $N$ is the number of nodes, $I$ is an identity matrix, and $\\alpha \\in [0,1]$. In general, this is _not_ a Markov matrix, and its largest eigenvalue (called the _dominant eigenvalue_) is strictly less than one. Actually, all eigenvalues are inside the unit circle; consequently, it can be shown that _every_ fixed point sequence converges to the zero vector. And that would make the page rank of every page equal zero. Since every fixed point sequence converges to the zero vector when $\\alpha < 1$, generally $\\alpha$ is called a _damping factor._ \n",
    "\n",
    "But buried in the Patent application is \n",
    "\n",
    "\"_Note that in order to ensure convergence, the norm of p, must be made equal to 1  after each iteration_\"\n",
    "\n",
    "And this means that the original method modifies the fixed point sequence by dividing each term fixed point sequence by a norm (which norm, the one, two, or infinity,  doesn't matter). This is known as the power method for finding the dominant eigenvalue (see https://en.wikipedia.org/wiki/Power_iteration).\n",
    "\n",
    "With or without a damping factor, the matrix used can have two or more linearly independent eigenvectors corresponding to the eigenvalue with the greatest magnitude. This happens, for example, when there are two or more nonempty disjoint sets of web pages (call them clusters) that are linked to other members of the subset, but not other clusters. Here is an example\n",
    "\n",
    "\n",
    "We can see the need for a modification by considering the Markov matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Array{Int64,2}:\n",
       " 0  1  0  0\n",
       " 1  0  0  0\n",
       " 0  0  0  1\n",
       " 0  0  1  0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = [0 1 0 0; 1 0 0 0; 0 0 0 1; 0 0 1 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling these pages $A$ though $D$, we see that $A$ and $B$ are linked and $C$ and $D$ are linked, but these two sets of nodes aren't linked together. What about the eigenvalues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = eigen(M);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha! There are two eigenvectors with eigenvalue 1. Using one eigenvector, the rank of $A$ and $B$ tie, but the ranks of $C$ and $D$ are zero.  And the other eigenvector swaps this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " -0.9999999999999989\n",
       " -0.9999999999999989\n",
       "  1.0\n",
       "  1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Array{Float64,2}:\n",
       "  0.707107   0.0       0.707107  0.0\n",
       " -0.707107   0.0       0.707107  0.0\n",
       "  0.0        0.707107  0.0       0.707107\n",
       "  0.0       -0.707107  0.0       0.707107"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including a damping factor does still gives two linearly independent eigenvectors corresponding to the dominant eigenvalue.  \n",
    "\n",
    "One way to fix this is to have a fictitious ''super node'' that is linked to every page and every page is linked to the super node. Effectively, the super node idea then includes the possibility that a user will visit a page by entering a url instead of randomly clicking."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Google ranks, I suppose, tens of billions (maybe trillions?) or so of pages. Finding _all_ the eigenvalues of such a huge matrix isn't, I think, possible. And it isn't needed either. The iterative process can be done quickly to find the page rank. Reasonable estimates are that it takes Google a few weeks to construct the graph of links and a few days to compute the page ranks.\n",
    "\n",
    "The Google Page Rank is named partially in honor of Larry _Page,_  one of the co-founders of Google, not as you might guess after web _page._ But the idea of using eigenvalues to rank options was popularized by the mathematician Thomas Saaty _decades_ before Google used it to rank pages. Stigler's law of eponymy says that \"states that no scientific discovery is named after its original discoverer.\" (https://en.wikipedia.org/wiki/Stigler%27s_law_of_eponymy). And so it is with the Google Page Rank.\n",
    "\n",
    "The history of the concept of an eigenvalue goes back to at least Euler (1707 – 1783). About 230 years after Euler used eigenvectors and eigevalues to describe the motion of ridge bodies, Larry Page, used the same concept to launch one of the largest companies of all time.\n",
    "\n",
    "For more information, see https://en.wikipedia.org/wiki/PageRank ; and see https://en.wikipedia.org/wiki/Thomas_L._Saaty\n",
    "\n",
    "Here is an example that shows that including a damping factor does not alter the fact that $M$ has two linearly independent eigenvectors corresponding to the dominant eigenvalue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Array{Float64,2}:\n",
       " 0.0375  0.85    0.0     0.0\n",
       " 0.85    0.0375  0.0     0.0\n",
       " 0.0     0.0     0.0375  0.85\n",
       " 0.0     0.0     0.85    0.0375"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = alpha/ N * I + (1-alpha) * M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eigen{Float64,Float64,Array{Float64,2},Array{Float64,1}}\n",
       "values:\n",
       "4-element Array{Float64,1}:\n",
       " -0.8124999999999989\n",
       " -0.8124999999999989\n",
       "  0.8875\n",
       "  0.8875\n",
       "vectors:\n",
       "4×4 Array{Float64,2}:\n",
       "  0.707107   0.0       0.707107  0.0\n",
       " -0.707107   0.0       0.707107  0.0\n",
       "  0.0        0.707107  0.0       0.707107\n",
       "  0.0       -0.707107  0.0       0.707107"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigen(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
