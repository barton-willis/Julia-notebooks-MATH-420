{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backwards Euler\n",
    "\n",
    "__MATH 420__ <br>\n",
    "_Spring 2021_ <br>\n",
    "\n",
    "I know what you are thinking: If we can base a solver for an initial  value problem (IVP) on the left point integration rule, we should be able to do the same for the right point integration rule.  Let's try. For the IVP\n",
    "\\begin{equation}\n",
    "  \\frac{\\mathrm{d} y}{\\mathrm{d} t} = F(t,y),  \\quad y = y_0 \\mbox{ when } t = t_0,\n",
    "\\end{equation}\n",
    "we'll integrate this equation using the right point integration rule. We have\n",
    "\\begin{equation}\n",
    "    \\int_{t_k}^{t_{k+1}} \\frac{\\mathrm{d} y}{\\mathrm{d} t} \\, \\mathrm{d} t = \\int_{t_k}^{t_{k+1}} F(t,y) \\mathrm{d} t.\n",
    "\\end{equation}\n",
    "Again, for the integral on the right side, we need to remember that \\(y\\) depends on \\(t\\). Making this dependence explicit converts the above to \n",
    "\\begin{equation}\\label{first-step}\n",
    "    \\int_{t_k}^{t_{k+1}} \\frac{\\mathrm{d} y}{\\mathrm{d} t} \\, \\mathrm{d} t = \\int_{t_k}^{t_{k+1}} F(t,y(t)) \n",
    "    \\mathrm{d} t.\n",
    "\\end{equation}\n",
    "The left side Eq.(\\ref{first-step}) is the integral of a derivative, so the fundamental theorem of calculus (FTC) gives its exact value.  For the integral on the right side, we approximate it using the right point integration rule. Putting these together yields\n",
    "\\begin{equation}\n",
    "    y_{k+1} - y_k  \\approx (t_{k+1} - t_k) F(t_{k+1},y_{k+1}).\n",
    "\\end{equation}\n",
    "Remember that for right point rule integration, the approximate value is width times the integrand evaluated at the upper limit of integration. Assuming a constant value for the width \\( t_{k+1} - t_k\\) and adding \\(y_{k} \\) to both sides of the approximate equality gives\n",
    "\\begin{equation}\n",
    "    y_{k+1} \\approx  y_k  + h F(t_{k+1},y_{k+1}), \n",
    "\\end{equation}\n",
    "where \\(h = t_{k+1} - t_k  \\). \n",
    "We'll call this the \\emph{backward Euler method}.  Actually, maybe we should puts hats on the \\(y \\) values to distinguish the approximate value from the true value.  And if we do that, we can replace approximate equality with equality too. This gives\n",
    "\\begin{equation}\\label{backwards}\n",
    "    \\widehat y_{k+1} =  \\widehat y_k  + h F(t_{k+1},\\widehat y_{k+1}).\n",
    "\\end{equation}\n",
    "But we have a problem. In Eq.(\\ref{backwards}), the unknown \\( \\widehat y_{k+1}\\) appears on both the left side of the equation \\emph{and} on the right side buried inside the function \\(F\\). Unless the function \\(F\\) is especially simple, solving this equation for \\( \\widehat y_{k+1} \\) isn't easy. \n",
    "\n",
    "One possibility is that we could use  a numerical method (fixed point iteration or the Newton method) to solve \n",
    "\\begin{equation}\n",
    "     \\widehat y_{k+1} =   \\widehat y_k  + h F(t_{k+1}, \\widehat y_{k+1}), \n",
    "\\end{equation}\n",
    "for \\( \\widehat y_{k+1}\\). But all such methods require an initial guess for the solution and without additional conditions (that might not be true) none of them are guaranteed to converge, even when a solution exists. So let's reject using a numerical method to solve for the unknown.\n",
    "\n",
    "As an alternative, let's try something tricky. For  the \\( \\widehat y_{k+1} \\) in  \\(F(t,y_{k+1}) \\), let's use the value we would get using the Euler method; recall that value is\n",
    "\\begin{equation}\n",
    "    y_{k+1} \\approx  y_k  + h F(t_k,y_{k}).\n",
    "\\end{equation}\n",
    "Substituting this value for \\( \\widehat y_{k+1} \\) into only the right side of Eq.(\\ref{backwards}) gives\n",
    "\\begin{equation}\n",
    "     \\widehat y_{k+1} =    \\widehat y_k  + h F(t_{k+1}, y_k  + h F(t_k,  \\widehat y_{k}) ).\n",
    "\\end{equation}\n",
    "Finally maybe on the right side we should replace \\(t_{k+1} \\) by \\(t_k + h\\).  That makes the right side purely defined interms of \\(t_k\\) and \\(y_k\\).  Thus\n",
    "\\begin{equation}\\label{RK1}\n",
    "     \\widehat y_{k+1} =    \\widehat y_k  + h F(t_{k} + h, y_k  + h F(t_k,  \\widehat y_{k}) ).\n",
    "\\end{equation}\n",
    "Now we have been able to solve for the unknown \\(  \\widehat y_{k+1} \\). So this is an \\emph{explicit method}.  Specifically it is an \\emph{explicit Runge-Kutta (RK) method}. There are many different RK methods--this one is the maybe the simplest. Specifically, we'll call this the RK-1 method. \n",
    "\n",
    "Why do we call this the RK-1 method? A Taylor expansion in powers of \\(h\\) of the true solution is\n",
    "\\begin{align}\n",
    "    y(t+h) &= y(t) + h \\frac{\\mathrm{d} y}{\\mathrm{d} t} (t) + \\mathrm{O}(h^2) , \\\\\n",
    "           &= y(t) + h F(t, y(t)) + \\mathrm{O(h^2)}.\n",
    " \\end{align}\n",
    " Thus for the true solution we have \n",
    "\\begin{equation}\n",
    "    y_{k+1} = y_k + h  F(t, y_k) + \\mathrm{O(h^2)}.\n",
    "\\end{equation}\n",
    "Done by hand, it's not particularly fun, but expanding \\( \\widehat y_k  + h F(t_{k} + h, y_k  + h F(t_k,  \\widehat y_{k}) \\) in powers of \\(h\\) gives\n",
    "\\begin{equation}\n",
    "     \\widehat y_{k+1} = \\widehat y_k  + h F(t_{k},y_k) + \\mathrm{O}(h^2).\n",
    "\\end{equation}\n",
    "And if we were to calculate the \\(h^2\\) term for both the true solution and the RK-1 solution, we would find that the \n",
    "\\(h^2\\) terms do not match. So we say that the RK-1 method?  Since the \\(h\\) terms of the true and approximate solution are equal, but the \\(h^2\\) terms are different, we say the RK-1 method is a first order method in the step size. So the one in RK-1 means that it is a first order method. When we discover an RK method that matches both the coefficient of \\(h\\) and that of \\(h^2\\), but not the \\(h^3\\) coefficient, we'll call it an RK-2 method.\n",
    "\n",
    "Here is a simple Julia function for our RK method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function rk1(F::Function, t0::Number, y0::Number, t1::Number, N::Integer)\n",
    "    (t0, y0, t1) = promote(t0,y0,t1) #promote all numbers to the same type\n",
    "    ya = Array{typeof(t0),1}(undef, N) \n",
    "    ta = Array{typeof(t0),1}(undef, N)\n",
    "    h = (t1-t0)/N\n",
    "    j = 1\n",
    "    while j <= N\n",
    "        ya[j] = y0    \n",
    "        ta[j] = t0\n",
    "        t1 = t0 + h\n",
    "        y0 += h*F(t1, y0 + h*F(t0, y0))\n",
    "        t0 = t1\n",
    "        j += 1\n",
    "    end\n",
    "    ta, ya\n",
    "end  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function euler_method(f::Function, t0::Number, y0::Number, t1::Number, N::Integer)\n",
    "    (t0, y0, t1) = promote(t0,y0,t1) #promote all numbers to the same type\n",
    "    ya = Array{typeof(t0),1}(undef, N) \n",
    "    ta = Array{typeof(t0),1}(undef, N)\n",
    "    h = (t1 - t0)/N\n",
    "    j = 1\n",
    "    while j <= N\n",
    "        ya[j] = y0    \n",
    "        ta[j] = t0\n",
    "        y0 += h*f(t0,y0)\n",
    "        t0 += h \n",
    "        j += 1\n",
    "    end\n",
    "    ta, ya\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument to `euler_method` is a function of two variables. Let's give our code an easy test; our DE is\n",
    "$$\n",
    "   \\frac{\\mathrm{d} y}{ \\mathrm{d} t} \\mathrm{d} t = 1, \\quad y = 1.5 \\mbox{  when } t = 0\n",
    "$$ \n",
    "We'll solve this DE (actually it's an initial value problem (IVP) because we have given one point on the solution curve) on the interval \\([0,2]\\) using 10 steps.  The solution to the IVP is\n",
    "$$\n",
    "    y(t) = \\frac{3}{2} + t.\n",
    "$$\n",
    "Let's try both the Euler Method and the RK-1 method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, t0, y0, tf, N = (t,y) -> 1, 0, 1.5, 2.0, 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = euler_method(F, t0, y0, tf, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX, YY = rk1(F, t0, y0, tf, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two methods give identical results--makes me wonder why we bothered.  \n",
    "\n",
    "Let's try both methods on the IVP\n",
    "$$\n",
    "   \\frac{\\mathrm{d} y}{ \\mathrm{d} t} \\mathrm{d} t = y, \\quad y =  1 \\mbox{  when } t = 0\n",
    "$$   \n",
    " The solution to the IVP is\n",
    "$$\n",
    "    y(t) = \\exp(t)\n",
    "$$\n",
    "We'll use $t_0 = 0, y_0 = 1, t_f = 2$, and $N = 20.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, t0, y0, tf, N = (t,y) -> y, 0.0, 1.0, 2.0, 20;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = euler_method(F, t0,y0, tf, N);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX, YY = rk1(F,  t0,y0, tf, N);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OK-for this IVP, the Euler method and the RK-1 method give somewhat different values.  Let's look at them graphically. But first, let's create arrays of the exact solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xe = [t0 + (tf - t0) * k /N for k in 0:N];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ye = map(t -> y0* exp(t), Xe);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gadfly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(layer(x=X, y=Y,Geom.point, color=[colorant\"blue\"] ), layer(x=XX, y=YY, color=[colorant\"red\"],Geom.point),\n",
    "        layer(x = Xe, y = Ye,Geom.line),Guide.xlabel(\"Time\"), Guide.ylabel(\"y(t)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Euler method (blue dots) are too small and the RK-1 method (red dots) are too large. This suggests using the average of the two methods.  What might that be?  The average of the left point integration rule and the right point rule is the trapezoidal  rule.  That, to me, sounds like homework.\n",
    "\n",
    "Finally, we show that if we make the step size large, the RK-1 method can give a terribly inaccurate result.  For the IVP\n",
    "$$\n",
    "   \\frac{\\mathrm{d} y}{ \\mathrm{d} t} \\mathrm{d} t = -y, \\quad y =  1 \\mbox{  when } t = 0\n",
    "$$\n",
    "The solution to the IVP is\n",
    "$$\n",
    "    y(t) = \\exp(-t)\n",
    "$$\n",
    "We'll use $t_0 = 0, y_0 = 1, t_f = 11$, and $N = 10$. That gives a step size of 1.1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, t0, y0, tf, N = (t,y) -> -y, 0.0, 1.0, 11.0, 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xe = [t0 + (tf - t0) * k /N for k in 0:N];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ye = map(t -> y0 * exp(-t), Xe);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX, YY = rk1(F,  t0, y0, tf, N);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(layer(x=XX, y=YY,Geom.point, color=[colorant\"blue\"] ), layer(x = Xe, y = Ye,Geom.line),Guide.xlabel(\"Time\"), Guide.ylabel(\"y(t)\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A giant oops. For a step size of 1.1, RK-1 solution grows exponentially, but true solution decays exponentially. We desperately  need a theory behind all this.  Reducing the step size to 0.11 fixes this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, t0, y0, tf, N = (t,y) -> -y, 0.0, 1.0, 11.0, 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xe = [t0 + (tf - t0) * k /N for k in 0:N];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ye = map(t -> y0 * exp(-t), Xe);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX, YY = rk1(F,  t0, y0, tf, N);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(layer(x=XX, y=YY,Geom.point, color=[colorant\"blue\"] ), layer(x = Xe, y = Ye,Geom.line),Guide.xlabel(\"Time\"), Guide.ylabel(\"y(t)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
